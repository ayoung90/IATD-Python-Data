{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rarely get our data in just the form we want.  In this worksheet we will investigate some techniques for making relatively simple adjustments that help us get _from our input data into a data frame that is ready for us to use_.\n",
    "\n",
    "We have some data in the file `iris.csv` which has been hand-transcribed from notebooks and contains a few errors.  To clean the data we will:\n",
    "  * Load up the data\n",
    "  * Understand the Data\n",
    "  * Remove empty values\n",
    "  * Fix format errors\n",
    "  * Fix incorrect data\n",
    "  * Remove duplicates\n",
    "\n",
    "After this, we are ready to visualise the data (which we will learn more about next week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data - notice that iris data has no index, so we will use a fresh one\n",
    "iris = pd.read_csv(\"data/iris.csv\")\n",
    "iris\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter always gives us a preview of our data when we print it, but we can specifially ask for the `head` rows, the `tail` rows and `info` about any dataframe.  `info` in particular gives us very useful information about our data.  Pay close attention to the \"non-null\" count and the data type of each column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data - notice that iris data has no index, so we will use a fresh one\n",
    "iris = pd.read_csv(\"data/iris.csv\")\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.head(2))\n",
    "print(\"\")\n",
    "print(iris.tail(2))\n",
    "print(\"\")\n",
    "print(iris.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The first issue that shows up is the missing value in \"sepal width\".  Every other column has 152 values, but this one has just 151.  Missing values in a table are called \"null\" values and they can mess with our analysis if we are not aware of them.  Sometimes we do want to leave them there, but often we want to exclude that data.\n",
    "\n",
    "**YOU MUST NEVER MODIFY YOUR SOURCE DATA**\n",
    "\n",
    "If there is \"junk\" in your input file, never make changes directly in the file, for the following reasons:\n",
    "  * data is often audited and modification of official data could be an infringement\n",
    "  * one person's junk is another person's treasure\n",
    "  * pandas can adjust the data for you easily so you can have a \"clean\" version without adjusting the original\n",
    "\n",
    "Lets start by finding that null value.  We know it is in the \"sepal width\" series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[\"sepal width\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can't see it in the preview, but pandas can filter a series to keep only the null values, but do that, we will need to understand indexing with masks.   \n",
    "\n",
    "Firstly, we get the \"sepal width\" series from the data frame.  Then we call a function on that series which will convert all values to true or false.  If the original value was not null, we will get false, if it was null, we get true.  You will have to believe me, but there is a single \"True\" in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = iris[\"sepal width\"].isnull()\n",
    "\n",
    "print(mask.info())\n",
    "\n",
    "mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we call a series that is all booleans a \"mask\". Only indexes with a \"True\" in the mask result in a row being included in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[mask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and thus we can see our problem.  There is a number missing in row 128.  Check the original dataframe to see for yourself.  We can also use `loc` or `iloc` to see the rows in this vicinity now we have identified the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.loc[120:130,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - wide petals\n",
    "\n",
    "Identify all rows where the \"petal width\" is greater than 5.  How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"put your answer in this code block\")\n",
    "\n",
    "mask = iris[\"petal width\"] > 5\n",
    "count = len(iris[mask].axes[0])\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the error\n",
    "\n",
    "What do to about the error is up to you.  You should create a \"clean\" data frame, separate to the other one regardless of your decision.  Possible choices are:\n",
    "  * remove that whole row\n",
    "  * remove that whole column\n",
    "  * choose a value for the missing entry\n",
    "\n",
    "We will demonstrate each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove that row\n",
    "\n",
    "# we need the opposite mask. A trick to do this is to perform the \"equals false\" operation :)\n",
    "mask2 = mask == False\n",
    "\n",
    "# we can then use this as a mask to get only the rows we want.\n",
    "clean_iris = iris[mask2]\n",
    "clean_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative!  Since we know exactly what row to drop, we can use the drop function\n",
    "\n",
    "clean_iris = iris.drop(index=126)\n",
    "clean_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative - dropna does _all_ the hard work for us\n",
    "clean_iris = iris.dropna()\n",
    "clean_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whole column with drop\n",
    "\n",
    "clean_iris = iris.drop(columns=\"sepal width\")\n",
    "clean_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a value for the missing entry with `fillna`\n",
    "clean_iris = iris.fillna(0)\n",
    "clean_iris.loc[125:128]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a couple of helper functions. [`dropna` will remove any rows with empty data](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) while [`fillna` will replace any empty values with some other value](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html).\n",
    "\n",
    "I tend not to fill in missing values, I tend to drop the whole row - that should be your default option but don't do it without paying attention to what is dropped and why.  Too many people just apply `dropna` without thinking."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - find errors\n",
    "\n",
    "Identify the erroneous data in the `class` column and remove that row.\n",
    "\n",
    "**Advanced** Imagine you had not seen the error, what type of pandas code could you construct to find such an error.  I would suggest extracting that column as a series, get all the unique values in the series (`drop_duplicates` will help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"put your solution here\")\n",
    "\n",
    "unique = iris[\"class\"].drop_duplicates()\n",
    "\n",
    "#invalid row below\n",
    "#124                6.3\n",
    "\n",
    "#remove index 124\n",
    "clean_iris = iris.drop(index=124)\n",
    "\n",
    "#check again\n",
    "\n",
    "unique = clean_iris[\"class\"].drop_duplicates()\n",
    "\n",
    "unique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - fishing\n",
    "\n",
    "**Advanced** Find any other erroneous data and fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"put your solution here\")\n",
    "\n",
    "# check data - there is a max petal width  = 22! where the mean = 1.3..\n",
    "clean_iris.describe()\n",
    "\n",
    "# find error\n",
    "mask = clean_iris[\"petal width\"] == 22\n",
    "drop_index = clean_iris[mask].index\n",
    "\n",
    "cleaner_iris = clean_iris.drop(index = drop_index)\n",
    "\n",
    "#petal width max now = 2.5\n",
    "cleaner_iris.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "There is a very useful method available on dataframes called \"describe\".  Below is an example of its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/rainfall/lithgow.csv was not provided\n",
    "# replaced with a different CSV\n",
    "lithgow = pd.read_csv(\"data/rainfall/IDCJAC0009_047045_1800_Data.csv\")\n",
    "lithgow.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with this method on data you know well, [check the documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html).  How do you think this method can help you find erroneous data in your DataFrames?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Summary\n",
    "  * We can index into a table with a mask\n",
    "  * We can use boolean operators to create useful masks\n",
    "  * `head`, `tail`, and `info` are useful for learning about your data\n",
    "  * `dropna`, `drop_duplicates`, `duplicates`, `fillna` are usefull for cleaning your data\n",
    "\n",
    "# Python concepts\n",
    "  * `head`, `tail`, `info`, `dropna`, `drop_duplicates`, `duplicates`, `fillna` are all _methods_ on the data frame object\n",
    "  * most of the methods we used returned entirely fresh values which we needed to capture in a new variable.  The original data frame was not changed by methods like `fillna`.\n",
    "  * the `drop` method of a dataframe can take different parameters to do different things.  `index=` will drop a row, `columns=` will drop a column.  Both versions return a whole new DataFrame, leaving the original untouched.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
